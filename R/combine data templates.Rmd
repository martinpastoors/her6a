---
output:
  word_document: 
    reference_docx: my_template.dotx
---


```{r setup, include=FALSE}

require("knitr")
knitr::opts_chunk$set(crop = TRUE, echo = FALSE, message=FALSE, warning=FALSE)
knit_hooks$set(crop = hook_pdfcrop)

```


```{r, message=FALSE, warning=FALSE, include=FALSE}

# ==================================================================
# Combine data templates.r
# 
# Read data and convert to RData sets
#
# Martin Pastoors
#
# 01/11/2016 initial coding
# 06/03/2017 adapted for final report
# 06/04/2017 checking number of samples
# 26/09/2017 reading the 2017 data
# 06/10/2017 finalized reading 2017 data
# 20/10/2017 converted to rMarkdown
# ==================================================================

# Reset lists
rm(list=ls())

library(sp)            # e.g. point in polygon
library(readxl)        # Hadleys simple package for reading excel
library(lubridate)     # date functions
library(stringr)       # string manipulation
library(pander)        # for tables
library(tidyverse)     # dplyr, tidyr, ggplot etc. 

# library(gisland)
source("../../gisland/r/geo_inside.R")

# source utils
source("../../mptools/R/my_utils.r")

# get dropbox directory
dropboxdir <- paste(get_dropbox(), "/6a Herring survey planning", sep="")

# ================================================================================
# Set working directory and filename
# ================================================================================

# Working directory
# setwd("D:/Dropbox/6a Herring survey planning/2017/DATA/")
#  load the map files
load(paste(dropboxdir,"/GIS/world.europe.df.RData", sep=""))
load(paste(dropboxdir,"/GIS/eez.europe.df.RData", sep=""))
load(paste(dropboxdir,"/GIS/fao27.df.RData", sep=""))

load(paste(dropboxdir,"/GIS/fao.RData", sep=""))
load(paste(dropboxdir,"/GIS/icesrectangles.RData", sep=""))

# ================================================================================
# Read survey areas
# ================================================================================

areas <- 
  read.csv(file=paste(dropboxdir,"/2017/DATA/Survey areas 2017.csv", sep=""), 
           header=TRUE, stringsAsFactors = FALSE)

# ================================================================================
# Building up file list
# ================================================================================

file.list <- 
  list.files(path = paste(dropboxdir, "/2017/DATA/", sep=""),
             pattern="data template",recursive=F, full.names=TRUE, ignore.case=TRUE)

# ================================================================================
# read haul sheets
# ================================================================================

# i <- 1

j <- 0
for (i in 1:length(file.list)){   
  
  
  if ("Haul" %in% excel_sheets(file.list[i])) {
    j <- j+1
    tmp<- 
      read_excel(file.list[i], sheet="Haul", col_names=TRUE, 
                 col_types ="text", skip=0, range=cell_cols("A:AO") ) %>% 
      lowcase() %>% 
      mutate(file     = file.list[i],
             sheet    = "Haul") %>% 
      filter(!is.na(haul), !is.na(date)) %>% 
      select(one_of(colnames(.)[!grepl("x|X",colnames(.))]) ) %>% 
      data.frame() 

    print(file.list[i])
    # print(head(tmp))
    # glimpse(tmp)
    
    if (j==1) t<-tmp else t<-bind_rows(t,tmp)
  }
}

# rename and manipulate dataset
haul <- 
  t %>% 
  
  mutate(
    vessel       = gsub("\\s+", "", str_trim(toupper(vessel))),
    haul         = as.integer(haul),
    date         = as.Date(as.numeric(date), origin = "1899-12-30"),
    week         = week(date),
    shoottime    = as.numeric(shoottime),
    haultime     = as.numeric(haultime),
    surfacetemp  = as.numeric(surfacetemp),
    headlinetemp = as.numeric(headlinetemp),
    headlinedepth= as.numeric(headlinedepth),
    waterdepth   = as.numeric(waterdepth),
    meshsize     = as.numeric(meshsize),
    vertopening  = as.numeric(vertopening),
    horzopening  = as.numeric(horzopening),
    catch        = as.numeric(catch),
    typehaul     = ifelse(grepl("commercial",tolower(file)), "C",typehaul),
    typehaul     = ifelse(is.na(typehaul), "S", typehaul),
    plotlon      = as.numeric(plotlon),
    plotlat      = as.numeric(plotlat),
    division     = geo_inside(lon=plotlon, lat=plotlat, 
                              map=fao[fao@data$F_LEVEL=="DIVISION",], variable="F_DIVISION"),
    rect         = geo_inside(lon=plotlon, lat=plotlat, 
                              map=icesrectangles, variable="ICESNAME"),
    surveyarea   = 
      ifelse (point.in.polygon(plotlon, plotlat,
                              areas$long[areas$area==1], areas$lat[areas$area==1])>0, "1",NA),
    surveyarea   = 
      ifelse (point.in.polygon(plotlon, plotlat,
                               areas$long[areas$area==2], areas$lat[areas$area==2])>0, "2", surveyarea),
    surveyarea   = 
      ifelse (point.in.polygon(plotlon, plotlat,
                               areas$long[areas$area==3], areas$lat[areas$area==3])>0, "3",surveyarea),          
    surveyarea   = 
      ifelse (point.in.polygon(plotlon, plotlat, 
                               areas$long[areas$area==4], areas$lat[areas$area==4])>0, "4",surveyarea) )


# filter(t, vessel == "PD265") %>% View()
# filter(haul, vessel == "PD265") %>% View()

# save RData file
save(haul, file=paste(dropboxdir, "/2017/DATA/rdata/haul.RData", sep=""))

# ================================================================================
#  Reading bio data
# ================================================================================

# i <- 2

j <- 0
for (i in 1:length(file.list)){   
  
  print(file.list[i])
  
  if ("Bio" %in% excel_sheets(file.list[i])) {
    j <- j+1
    tmp <- 
      read_excel(file.list[i], sheet="Bio", col_names=TRUE, col_types="text", skip=0 ) %>% 
      lowcase() %>% 
      mutate(file   = file.list[i],
             sheet  = "Bio") %>% 
      filter(!is.na(haul)) %>% 
      data.frame()
    
    print(head(tmp))
    
    if (j==1) t<-tmp else t<-rbind.all.columns(t,tmp)
  }
}

# rename and manipulate dataset
bio <- 
  t %>% 
  rename(length = length.cm.,
         weight = weight.g.,
         mat    = maturitystage.1.9.) %>% 
  mutate(vessel = gsub("\\s+", "", str_trim(toupper(vessel))),
         haul   = as.integer(haul),
         date   = as.Date(as.numeric(date), origin = "1899-12-30"),
         fishid = as.integer(fishid),
         length = as.numeric(length),
         weight = ifelse(weight == 0, NA, weight),
         mat    = ifelse(mat == 0, NA, mat),
         fishid = as.numeric(fishid),
         age    = as.integer(age) )

# save RData file
save(bio, file=paste(dropboxdir, "/2017/DATA/rdata/bio.RData", sep=""))

# ================================================================================
# read length sheets
# ================================================================================

# i <- 1

j <- 0
for (i in 1:length(file.list)){   
  
  print(file.list[i])
  
  if ("L1" %in% excel_sheets(file.list[i])) {
    j <- j+1
    tmp<- 
      read_excel(file.list[i], sheet="L1", col_names=TRUE, col_types ="text", skip=0 ) %>% 
      lowcase() %>% 
      mutate(file   = file.list[i],
             sheet  = "Length") %>% 
      filter(!is.na(haul), !is.na(count), count != 0) %>% 
      data.frame()
    
    print(head(tmp))
    
    if (j==1) t<-tmp else t<-rbind.all.columns(t,tmp)
  }
}

# rename and manipulate dataset
length <- 
  t %>% 
  mutate(length = as.numeric(length),
         vessel = gsub("\\s+", "", str_trim(toupper(vessel))),
         haul   = as.integer(haul),
         sampleweight = as.numeric(sampleweight),
         date   = as.Date(as.numeric(date), origin = "1899-12-30"),
         count  = as.integer(count) ) %>% 
  filter(merk == "0")

# save RData file
save(length, file=paste(dropboxdir, "/2017/DATA/rdata/length.RData", sep=""))


```

# Herring 6a survey report 2017

## Overview of catch, sampling and biological information

Martin Pastoors

Date: `r format(Sys.time(), '%d/%m/%Y %X')`

### Introduction

### Data handling

### Results


```{r, echo=FALSE, message=FALSE, warning=FALSE}



```


```{r, echo=FALSE, fig.width=10, fig.asp=0.7, fig.align="center", message=FALSE, warning=FALSE}

# plot haul positions
haul %>%
  ggplot(aes(plotlon, plotlat)) + 
  theme_publication() +
  theme(strip.background = element_rect(colour=NA, fill = "#f0f0f0"),
        panel.border     = element_rect(colour="gray" , size=0.2),
        legend.title=element_blank() ) +
  
  coord_quickmap(xlim=c(-10,0) , ylim=c(56,60)) +
  geom_polygon(data=world.europe.df, aes(long, lat, group=group),
               fill = "lightgray", colour=NA) +
  geom_polygon(data=fao27.df,   aes(long, lat, group=group),
               fill = NA, size=0.3, colour="black") +
  geom_polygon(data=areas, aes(long, lat, group=area), colour="red", size=0.2,fill=NA) +
  geom_jitter(aes(colour=vessel), alpha = 0.6, size=2) +
  labs(x = NULL, y = NULL, title="2017 haul positions by vessel and week") +
  facet_wrap(~week)

```

_Figure 1: _


```{r, echo=FALSE, fig.width=10, fig.asp=0.7, fig.align="center", message=FALSE, warning=FALSE}

# plot survey and commerical catches
haul %>%
  ggplot(aes(plotlon, plotlat)) + 
  theme_publication() +
  theme(strip.background = element_rect(colour=NA, fill = "#f0f0f0"),
        panel.border     = element_rect(colour="gray" , size=0.2),
        legend.title=element_blank() ) +
  
  coord_quickmap(xlim=c(-10,0) , ylim=c(56,60)) +
  geom_polygon(data=world.europe.df, aes(long, lat, group=group),
               fill = "lightgray", colour=NA) +
  geom_polygon(data=fao27.df,   aes(long, lat, group=group),
               fill = NA, size=0.3, colour="black") +
  geom_polygon(data=areas, aes(long, lat, group=area), colour="red", size=0.2,fill=NA) +
  geom_jitter(aes(size=catch, colour=factor(typehaul)), alpha = 0.6) +
  labs(x = NULL, y = NULL, title="2017 catch (tonnes) in survey (S) and commercial (C) hauls by week") +
  guides(size = guide_legend(nrow = 1)) +
  facet_wrap(~week)

```

_Figure 2: _


```{r, echo=FALSE, fig.width=10, fig.asp=0.6, fig.align="center", message=FALSE, warning=FALSE}

# relative length distribution by vessel and division
length %>%
  select(-file, -sheet) %>% 
  left_join(haul, by=c("vessel","trip","haul","date")) %>% 
  mutate(raisingfactor = catch*1000/sampleweight, 
         countr        = count * raisingfactor) %>% 
  group_by(vessel, species, division, length) %>% 
  summarize(n = sum(countr, na.rm=TRUE)) %>% 
  group_by(vessel, species, division) %>% 
  mutate(prop = n / sum(n, na.rm=TRUE)) %>% 
  filter(species == "HER") %>% 
  
  ggplot(aes(x=length, y=prop)) + 
  theme_publication() +
  scale_x_reverse() +
  coord_flip() +
  geom_line(aes(colour=factor(vessel), group=factor(vessel))) +
  facet_grid(. ~ division)

```

_Figure 3: _

```{r, echo=FALSE, fig.width=10, fig.asp=0.6, fig.align="center", message=FALSE, warning=FALSE}

# relative length distribution by vessel and survey area
length %>%
  select(-file, -sheet) %>% 
  left_join(haul, by=c("vessel","trip","haul","date")) %>% 
  mutate(raisingfactor = catch*1000/sampleweight, 
         countr        = count * raisingfactor) %>% 
  group_by(vessel, species, surveyarea, length) %>% 
  summarize(n = sum(countr, na.rm=TRUE)) %>% 
  group_by(vessel, species, surveyarea) %>% 
  mutate(prop = n / sum(n, na.rm=TRUE)) %>% 
  filter(species == "HER") %>% 
  
  ggplot(aes(x=length, y=prop)) + 
  theme_publication() +
  scale_x_reverse() +
  coord_flip() +
  geom_line(aes(colour=factor(vessel), group=factor(vessel))) +
  facet_grid(. ~ surveyarea)

```

